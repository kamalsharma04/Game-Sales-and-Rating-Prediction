{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7478ffe6",
   "metadata": {},
   "source": [
    "\"\"\"-IMPORTING NECESSARY LIBRARIES-\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613870d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# Visualization libraries \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import plotly.express as px\n",
    "\n",
    "# Machine learning libraries \n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf955584",
   "metadata": {},
   "source": [
    "'''Reading dataset'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44360d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"D:\\portfolio project gmaes sales and ratting\\Video_Games.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29647a16",
   "metadata": {},
   "source": [
    "'''Understanding the dataset'''\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b38f5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "#print(df.info())\n",
    "#print(df.describe())\n",
    "print(df.isnull().sum())\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166d2f87",
   "metadata": {},
   "source": [
    "'''How many games with critic and User score available?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6542dbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_with_both = df[['Critic_Score', 'User_Score']].dropna()\n",
    "print(game_with_both.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d6a6c8",
   "metadata": {},
   "source": [
    "'''which publisher has the highest global sales?'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73da00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking any missing values in the columns 'Publisher' and 'Global_Sales' and removing them \n",
    "missing_value = df[[\"Publisher\",\"Global_Sales\"]].isnull().sum()\n",
    "cleaned_values = df.dropna(subset=[\"Publisher\"])\n",
    "\n",
    "# Aggregation of global sales by publisher\n",
    "global_sales = cleaned_values.groupby('Publisher')['Global_Sales'].sum().sort_values(ascending=False)\n",
    "\n",
    "# Prepare top 10 as a DataFrame for seaborn\n",
    "top10 = global_sales.head(10).reset_index()\n",
    "\n",
    "# Top 10 publishers with the highest global sales visualization\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(data=top10,\n",
    "            x='Publisher',\n",
    "            y='Global_Sales',\n",
    "            palette='viridis')\n",
    "plt.grid(linestyle=':', linewidth=1)\n",
    "plt.title('TOP 10 PUBLISHERS WITH THE HIGHEST GLOBAL SALES', fontsize=17)\n",
    "plt.xlabel('Names of the publishing companies',fontsize=13)\n",
    "plt.ylabel('Global sales by the publishing companies',fontsize=13)\n",
    "plt.xticks(rotation=35, ha='right',size=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#missing_value\n",
    "#cleaned_values\n",
    "top10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0ce23e",
   "metadata": {},
   "source": [
    "'''Which platform have the higest global sales?'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c211a6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking any null values\n",
    "platform_global_sales=df[['Platform','Global_Sales']].isnull().sum()\n",
    "\n",
    "# Aggrigation of the global sales by the platform\n",
    "platform_sales=df.groupby('Platform',as_index=False)['Global_Sales'].sum().sort_values(by='Global_Sales',ascending=False)\n",
    "top10platform=platform_sales.head(10)\n",
    "\n",
    "# Top 10 platform with the highest global sales visualization\n",
    "plt.Figure(figsize=(8,6))\n",
    "sns.barplot(data=top10platform,\n",
    "            x='Platform',\n",
    "            y='Global_Sales',\n",
    "            palette='bwr')\n",
    "plt.grid(linestyle=':',linewidth=1)\n",
    "plt.title('TOP 10 PLATFORMS WITH THE HIGHEST GLOBAL SALES',fontsize=17)\n",
    "plt.xlabel('Top 10 platforms',fontsize=13)\n",
    "plt.ylabel('Global sales',fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a676ba",
   "metadata": {},
   "source": [
    "'''Which Genre have the highest global sales?'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1967345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking and removing any null values\n",
    "genre_sales=df[['Genre','Global_Sales']].isnull().sum()\n",
    "clean_genre_sales=df.dropna(subset=['Genre'])\n",
    "clean_genre_sales['Genre'].isnull().sum()\n",
    "\n",
    "# Aggrigation of the global sales by Genre\n",
    "genre_global_sales=clean_genre_sales.groupby('Genre')['Global_Sales'].sum().sort_values(ascending=False)\n",
    "\n",
    "# Top 10 Genre with the highest global sales\n",
    "top10_genre=genre_global_sales.head(10).reset_index()\n",
    "\n",
    "# visualization\n",
    "fig=px.bar(top10_genre,\n",
    "           x='Genre',\n",
    "           y='Global_Sales',\n",
    "           color='Genre',\n",
    "           title='Top 10 Genre with the highest global sales',\n",
    "           labels={'Genre':'Game genre','Global sales':'Global sales in thousand units'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205d1521",
   "metadata": {},
   "source": [
    "'''Which feature correlates most with the high user score?'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2760f53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting 'User_Score' to numeric, forcing tbd to NaN\n",
    "df['User_Score']=pd.to_numeric(df['User_Score'],errors='coerce')\n",
    "\n",
    "# Initialzing LabelEncoder\n",
    "le=LabelEncoder()\n",
    "\n",
    "# loop through each column in the dataframe\n",
    "for column in df.columns:\n",
    "    # Check if the column is of object type\n",
    "    if df[column].dtype=='object':\n",
    "        # Converting object type columns to catagorical type \n",
    "        df[column]=df[column].astype('category')\n",
    "        # Applying labelEncoder to the column\n",
    "        df[column]=le.fit_transform(df[column])\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "top10_genre=genre_global_sales.head(10).reset_index()\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Visualizing the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(correlation_matrix,\n",
    "            annot=True,\n",
    "            annot_kws={'size':10},\n",
    "            cmap='coolwarm',\n",
    "            fmt='.2f',\n",
    "            linecolor='black',\n",
    "            linewidths=0.5,)\n",
    "plt.title('Correlation Matrix for All Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb532938",
   "metadata": {},
   "source": [
    "'''After seeing previous heat map selecting specific columns which do really relate to user score '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ffa379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selact only the specific columns\n",
    "specific_columns=['Name', 'Platform', 'Genre', 'Publisher', 'Global_Sales', 'Critic_Score', 'User_Score', 'Developer', 'Rating']\n",
    "# Adding specific columns to df \n",
    "df=df[specific_columns]\n",
    "\n",
    "# Changing tbd values to NaN\n",
    "df['User_Score']=pd.to_numeric(df['User_Score'],errors='coerce')\n",
    "\n",
    "# Saving labelEncoder as le \n",
    "le=LabelEncoder()\n",
    "\n",
    "# looping through each collumn\n",
    "for col in df.columns:\n",
    "    # Checking if the column has object values\n",
    "    if df[col].dtype=='object':\n",
    "        # Converting cbject type columns to categorical type\n",
    "        df[col]=df[col].astype('category').cat.codes.replace(-1, np.nan)\n",
    "        # Applying LabelEncoder to categorical type columns\n",
    "        df[col]=le.fit_transform(df[col])\n",
    "\n",
    "# Calculating the correlation matrix \n",
    "correlation_matrix=df.corr()\n",
    "\n",
    "# Visualizing the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(correlation_matrix,\n",
    "            cmap='coolwarm',\n",
    "            annot=True,\n",
    "            annot_kws={'size':10},\n",
    "            fmt='.2f',\n",
    "            linewidths=0.5,\n",
    "            linecolor='black')\n",
    "plt.title('Correlation Matrix for selacted columns')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593486de",
   "metadata": {},
   "source": [
    "'''Examine how the vedio game sales change over the year . Identifing the period of significant growth or decline in sales'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dd3466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data once again\n",
    "df=pd.read_csv(r\"D:\\portfolio project gmaes sales and ratting\\Video_Games.csv\")\n",
    "\n",
    "# Checking and removing null values\n",
    "sales_year_null=df[['Year_of_Release','Global_Sales']].isnull().sum()\n",
    "clean_sales_year_null=df['Year_of_Release'].dropna().astype(int)\n",
    "\n",
    "# checking the sales in years\n",
    "sales_years=df.groupby('Year_of_Release')['Global_Sales'].sum().sort_index()\n",
    "\n",
    "# visualizing\n",
    "plt.figure(figsize=(12,5))\n",
    "sales_years.plot(kind='line', marker='o')\n",
    "plt.xlabel(\"Year of Release\")\n",
    "plt.ylabel(\"Global Sales\")\n",
    "plt.title(\"Global Video Game Sales Over Years\")\n",
    "plt.axvspan(2005, 2008, color='green', alpha=0.2, label='Growth')\n",
    "plt.axvspan(2010, 2017, color='red', alpha=0.2, label='Decline')\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c48817",
   "metadata": {},
   "source": [
    "'''Compare the popularity of the genres or platform in the different regions'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b92ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting important columns and doing aggrigation\n",
    "pop_genre=df.groupby('Genre')[['NA_Sales','EU_Sales','JP_Sales','Other_Sales']].sum()\n",
    "\n",
    "# visulization\n",
    "pop_genre.plot(kind='bar',\n",
    "               figsize=(11,5))\n",
    "plt.grid(linestyle=\":\",linewidth=1)\n",
    "plt.title(\"Compare the popularity of the genres or platform in the different regions\")\n",
    "plt.xlabel(\"Genres\")\n",
    "plt.ylabel(\"All kind of sales\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20ae9ec",
   "metadata": {},
   "source": [
    "'''Correlation between user score and critic score also explor closely how user opinions align with profesional critic'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa468e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a copy of our orignal dataframe (df) so we wont make any change in our orignal data\n",
    "df_c=df.copy()\n",
    "\n",
    "# Selecting and removing null values from important columns\n",
    "sel_c=df_c[['User_Score','Critic_Score']].isnull().sum()\n",
    "clean_sel_c=df_c[['User_Score','Critic_Score']].dropna()\n",
    "\n",
    "# Converting object values to numerical like tbd to NaN\n",
    "clean_sel_c['User_Score'] = pd.to_numeric(clean_sel_c['User_Score'], errors='coerce')\n",
    "\n",
    "# Finding correlation between user score and critic score \n",
    "corr_c=clean_sel_c['User_Score'].corr(clean_sel_c['Critic_Score'])\n",
    "\n",
    "# visulization\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.scatter(x = clean_sel_c['User_Score'] + np.random.normal(0, 0.1, len(clean_sel_c)),\n",
    "            y = clean_sel_c['Critic_Score'] + np.random.normal(0, 0.1, len(clean_sel_c)),\n",
    "            alpha=0.5,\n",
    "            color='g')\n",
    "plt.xlabel('User Score')\n",
    "plt.ylabel('Critic Score')\n",
    "plt.title(f'User vs Critic Scores (Correlation: {corr_c:.2f})')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "                                                                        # optional\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.hexbin(clean_sel_c['User_Score'],\n",
    "           clean_sel_c['Critic_Score'],\n",
    "           gridsize=25,\n",
    "           cmap='Blues')\n",
    "plt.colorbar(label='Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6642b881",
   "metadata": {},
   "source": [
    "'''Machine learning model to predict future sales based on various features'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f17509c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing machine learning libraries\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler,OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix,classification_report,mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130657a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a copy of our orignal dataframe (df) so we wont make any change in our orignal data\n",
    "df_d = df.copy()\n",
    "\n",
    "# Selecting features and target\n",
    "features=df_d[['Platform', 'Genre', 'Publisher', 'Critic_Score', 'User_Score','Rating','Year_of_Release','Developer']]\n",
    "target=df_d['Global_Sales']\n",
    "\n",
    "# Handling missing values\n",
    "features = features.copy()\n",
    "features['User_Score']=pd.to_numeric(features['User_Score'],errors='coerce')\n",
    "features_c=features.dropna()\n",
    "target_clean=df_d.loc[features_c.index,'Global_Sales']\n",
    "\n",
    "# Separating Categorical and Numerical Columns\n",
    "features_numerical=['User_Score','Critic_Score','Year_of_Release']\n",
    "categorical_features=['Platform','Genre','Publisher','Rating','Developer']\n",
    "\n",
    "# Using pipelines\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "categorical_transformer= Pipeline(steps=[\n",
    "        ('imputer',SimpleImputer(strategy='constant',fill_value='missing')),\n",
    "        ('oneencoder',OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, features_numerical),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# Create the preprocessing and training pipeline\n",
    "model=Pipeline(steps=[\n",
    "    ('preprocessior',preprocessor),\n",
    "    ('regresion', RandomForestRegressor(n_estimators=40, random_state=42))\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train ,X_test ,y_train ,y_test=train_test_split(features_c,\n",
    "                                                  target_clean,\n",
    "                                                  test_size=0.2,\n",
    "                                                  random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pre=model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse=mean_squared_error(y_pre,y_test)\n",
    "rmse=mse**0.5\n",
    "\n",
    "# Printing result\n",
    "print('mse:',mse)\n",
    "print('rmse:',rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
